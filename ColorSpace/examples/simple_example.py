#!/usr/bin/env python3
"""
ç®€å•ä½¿ç”¨ç¤ºä¾‹ï¼šåŸºæœ¬çš„è‰²åŸŸæ˜ å°„
æ¼”ç¤ºæœ€åŸºç¡€çš„BT.2020åˆ°sRGBæ˜ å°„
"""

import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥ä¸»è¦åŠŸèƒ½
from models.pytorch_model import create_pytorch_mapper
from data.sampler import create_sampler
from core.color_conversion import bt2020_to_srgb_direct, delta_e_cie94, rgb_to_lab


def main():
    """ç®€å•ç¤ºä¾‹ä¸»å‡½æ•°"""
    print("ðŸŽ¨ è‰²åŸŸæ˜ å°„ç®€å•ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡åž‹
    print("1. åˆ›å»ºBT.2020åˆ°sRGBæ˜ å°„æ¨¡åž‹...")
    model = create_pytorch_mapper(
        source_gamut='bt2020',
        target_gamut='srgb',
        deltaE_threshold=3.0,  # å…è®¸çš„æœ€å¤§è‰²å½©åå·®
        device='auto'  # è‡ªåŠ¨æ£€æµ‹GPU
    )
    
    # 2. å‡†å¤‡è®­ç»ƒæ•°æ®
    print("2. å‡†å¤‡è®­ç»ƒæ•°æ®...")
    train_sampler = create_sampler('bt2020', 'srgb', 'perceptual')
    val_sampler = create_sampler('bt2020', 'srgb', 'uniform')
    
    # 3. è®­ç»ƒæ¨¡åž‹
    print("3. å¼€å§‹è®­ç»ƒ (å¿«é€Ÿæ¼”ç¤ºï¼Œä»…20è½®)...")
    history = model.train(
        train_sampler=train_sampler,
        validation_sampler=val_sampler,
        epochs=20,
        batch_size=512,
        learning_rate=0.005,
        verbose=True
    )
    
    # 4. æµ‹è¯•æ¨¡åž‹
    print("\n4. æµ‹è¯•æ¨¡åž‹æ€§èƒ½...")
    
    # ç”Ÿæˆæµ‹è¯•é¢œè‰²
    test_colors_bt2020 = np.array([
        [1.0, 0.0, 0.0],  # çº¯çº¢
        [0.0, 1.0, 0.0],  # çº¯ç»¿
        [0.0, 0.0, 1.0],  # çº¯è“
        [1.0, 1.0, 0.0],  # é»„è‰²
        [1.0, 0.0, 1.0],  # å“çº¢
        [0.0, 1.0, 1.0],  # é’è‰²
        [0.8, 0.2, 0.4],  # è‡ªå®šä¹‰é¢œè‰²1
        [0.3, 0.7, 0.9],  # è‡ªå®šä¹‰é¢œè‰²2
    ])
    
    # ä½¿ç”¨æ¨¡åž‹è¿›è¡Œæ˜ å°„
    mapped_colors_srgb = model.transform(test_colors_bt2020)
    
    # å¯¹æ¯”ä¼ ç»Ÿçš„ç›´æŽ¥è½¬æ¢
    direct_colors_srgb = bt2020_to_srgb_direct(test_colors_bt2020)
    
    print("\næ˜ å°„ç»“æžœå¯¹æ¯”:")
    print("BT.2020 åŽŸè‰²  â†’  ç¥žç»ç½‘ç»œæ˜ å°„  â†’  ç›´æŽ¥æ•°å­¦è½¬æ¢")
    print("-" * 60)
    
    for i, (bt2020, nn_mapped, direct) in enumerate(
        zip(test_colors_bt2020, mapped_colors_srgb, direct_colors_srgb)
    ):
        print(f"é¢œè‰² {i+1}: {bt2020} â†’ {nn_mapped} â†’ {direct}")
    
    # 5. è¯„ä¼°è‰²å½©è´¨é‡
    print("\n5. è‰²å½©è´¨é‡è¯„ä¼°...")
    
    # è®¡ç®—deltaE
    bt2020_lab = rgb_to_lab(test_colors_bt2020, 'bt2020')
    mapped_lab = rgb_to_lab(mapped_colors_srgb, 'srgb')
    direct_lab = rgb_to_lab(direct_colors_srgb, 'srgb')
    
    deltaE_nn = delta_e_cie94(bt2020_lab, mapped_lab)
    deltaE_direct = delta_e_cie94(bt2020_lab, direct_lab)
    
    print(f"ç¥žç»ç½‘ç»œæ˜ å°„å¹³å‡deltaE: {np.mean(deltaE_nn):.3f}")
    print(f"ç›´æŽ¥è½¬æ¢å¹³å‡deltaE: {np.mean(deltaE_direct):.3f}")
    print(f"ç¥žç»ç½‘ç»œæœ€å¤§deltaE: {np.max(deltaE_nn):.3f}")
    print(f"ç›´æŽ¥è½¬æ¢æœ€å¤§deltaE: {np.max(deltaE_direct):.3f}")
    
    # æ£€æŸ¥è‰²åŸŸè¦†ç›–
    nn_in_gamut = np.all((mapped_colors_srgb >= 0) & (mapped_colors_srgb <= 1), axis=1)
    direct_in_gamut = np.all((direct_colors_srgb >= 0) & (direct_colors_srgb <= 1), axis=1)
    
    print(f"ç¥žç»ç½‘ç»œæ˜ å°„è‰²åŸŸå†…æ¯”ä¾‹: {np.mean(nn_in_gamut):.3f}")
    print(f"ç›´æŽ¥è½¬æ¢è‰²åŸŸå†…æ¯”ä¾‹: {np.mean(direct_in_gamut):.3f}")
    
    # 6. ä¿å­˜æ¨¡åž‹ (å¯é€‰)
    print("\n6. ä¿å­˜æ¨¡åž‹...")
    output_dir = './simple_example_output'
    os.makedirs(output_dir, exist_ok=True)
    
    model_path = os.path.join(output_dir, 'bt2020_to_srgb_model.pth')
    model.save_model(model_path)
    print(f"æ¨¡åž‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # 7. å®žé™…ä½¿ç”¨æ¼”ç¤º
    print("\n7. å®žé™…ä½¿ç”¨æ¼”ç¤º - æ‰¹é‡å¤„ç†å›¾åƒåƒç´ ...")
    
    # æ¨¡æ‹Ÿä¸€äº›å›¾åƒåƒç´  (éšæœºBT.2020é¢œè‰²)
    np.random.seed(42)
    image_pixels = np.random.rand(1000, 3)  # 1000ä¸ªåƒç´ 
    
    # ä½¿ç”¨æ¨¡åž‹è¿›è¡Œæ˜ å°„
    import time
    start_time = time.time()
    mapped_pixels = model.transform(image_pixels)
    processing_time = time.time() - start_time
    
    print(f"å¤„ç†äº† {len(image_pixels)} ä¸ªåƒç´ ")
    print(f"å¤„ç†æ—¶é—´: {processing_time*1000:.2f} ms")
    print(f"å¤„ç†é€Ÿåº¦: {len(image_pixels)/processing_time:.0f} åƒç´ /ç§’")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"æ˜ å°„åŽåƒç´ èŒƒå›´: [{mapped_pixels.min():.3f}, {mapped_pixels.max():.3f}]")
    
    print("\n" + "=" * 50)
    print("âœ… ç®€å•ç¤ºä¾‹å®Œæˆ!")
    print("ðŸ” ä¸»è¦ç‰¹æ€§:")
    print("   â€¢ æ„ŸçŸ¥å‡åŒ€æ€§ä¿æŒ (CIELABç©ºé—´å¤„ç†)")
    print("   â€¢ deltaEçº¦æŸæŽ§åˆ¶")
    print("   â€¢ é«˜æ•ˆçš„æ‰¹é‡å¤„ç†")
    print("   â€¢ ä¿æŒè‰²åŸŸè¾¹ç•Œ")
    
    print("\nðŸ“ ä¸‹ä¸€æ­¥:")
    print("   â€¢ å°è¯• examples/quickstart.py æŸ¥çœ‹å®Œæ•´åŠŸèƒ½")
    print("   â€¢ ä½¿ç”¨ training/train_pytorch.py è®­ç»ƒè‡ªå®šä¹‰æ¨¡åž‹")
    print("   â€¢ æŽ¢ç´¢å¤šé€šé“æ˜ å°„åŠŸèƒ½")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nå‡ºçŽ°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc() 